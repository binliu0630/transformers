{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMwKsuk/06vT/74zG1Ul3na",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binliu0630/transformers/blob/master/Transformer_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpSjplvG6Uok",
        "colab_type": "text"
      },
      "source": [
        "## Get Started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMaZf1gn6Knm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "9585d857-9d34-48ef-81ec-a8d8ddca5eff"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FenmoJ96aH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a04228ec-6fb8-469d-e303-af1422273562"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "  print(f'Found GPU at: {device_name}')\n",
        "else:\n",
        "  raise SystemError('GPU device not available')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_OwA2a666Px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWHnhOAn7Ta5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "90bccbe6-8233-4267-8da1-fdc94db71450"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print(f'There are {torch.cuda.device_count()} GPU(s) available')\n",
        "  print(f'We will use the GPU: {torch.cuda.get_device_name()} with the capacity of: {torch.cuda.get_device_capability()}')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print(f'No GPU is available, using CPU instead.')\n",
        "  \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available\n",
            "We will use the GPU: Tesla T4 with the capacity of: (7, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upia-6um8HNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "0206ef19-9e2a-4db6-b861-7922040f1072"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 27.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 8.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 10.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 67.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 71.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 63.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=6bc36451461b6aaecfdd7b36b93095321ce1f9bcb7ab25045fb1c4b194b3ebf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jElsj7ZT8QTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0cf23409-fd66-409a-aaba-2ed8079b2e4f"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=8e4cd10d3a8ed69142995da2185b3ea73b9c6d5add3431e698b385d12d55d8bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch5atpO-8Xqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wget\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joPeeGXv8dsk",
        "colab_type": "text"
      },
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSaUhPYl8sUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "  wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez645aJl8c4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "41c04076-49c3-48c9-bac1-f891249b655e"
      },
      "source": [
        "if not os.path.exists('./cola_public/'):\n",
        "  !unzip cola_public_1.1.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbRie0U68bG0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "0d111490-2f7d-4cf6-e901-fe585deab525"
      },
      "source": [
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "df.sample(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3934</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John disappeared.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2326</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The judge offered a prize to the winner.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7562</th>\n",
              "      <td>sks13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John's mother likes him.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6659</th>\n",
              "      <td>m_02</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The cat trotted into the kitchen.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4103</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>You should attempt answering every question.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8541</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Where has he put the cake?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5926</th>\n",
              "      <td>c_13</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>placed the flute on the table.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6240</th>\n",
              "      <td>c_13</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>It is reluctant that Jean left.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>gj04</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Harry coughed himself.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8291</th>\n",
              "      <td>ad03</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>We wanted to ate cake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                      sentence\n",
              "3934            ks08  ...                             John disappeared.\n",
              "2326            l-93  ...      The judge offered a prize to the winner.\n",
              "7562           sks13  ...                      John's mother likes him.\n",
              "6659            m_02  ...             The cat trotted into the kitchen.\n",
              "4103            ks08  ...  You should attempt answering every question.\n",
              "8541            ad03  ...                    Where has he put the cake?\n",
              "5926            c_13  ...                placed the flute on the table.\n",
              "6240            c_13  ...               It is reluctant that Jean left.\n",
              "25              gj04  ...                        Harry coughed himself.\n",
              "8291            ad03  ...                         We wanted to ate cake\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IPY4mX49njM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2eeebbb6-a942-45c2-cf43-203ebbde973f"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8551 entries, 0 to 8550\n",
            "Data columns (total 4 columns):\n",
            "sentence_source    8551 non-null object\n",
            "label              8551 non-null int64\n",
            "label_notes        2527 non-null object\n",
            "sentence           8551 non-null object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 267.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRN1m6M3-EYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}